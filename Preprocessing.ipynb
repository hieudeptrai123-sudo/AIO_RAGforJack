{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"include_colab_link":true},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/hieunguyen2208/preprocessing?scriptVersionId=204057273\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/hieudeptrai123-sudo/AIO_RAGforJack/blob/main/Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"code","source":"!pip install pyvi unidecode gdown\n!git clone https://github.com/hieudeptrai123-sudo/AIO_RAGforJack.git","metadata":{"id":"oY5DB0z2hKi4","execution":{"iopub.status.busy":"2024-10-29T05:34:39.009655Z","iopub.execute_input":"2024-10-29T05:34:39.010246Z","iopub.status.idle":"2024-10-29T05:34:51.96656Z","shell.execute_reply.started":"2024-10-29T05:34:39.010203Z","shell.execute_reply":"2024-10-29T05:34:51.965116Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pyvi in /opt/conda/lib/python3.10/site-packages (0.1.1)\nRequirement already satisfied: unidecode in /opt/conda/lib/python3.10/site-packages (1.3.8)\nRequirement already satisfied: gdown in /opt/conda/lib/python3.10/site-packages (5.2.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from pyvi) (1.2.2)\nRequirement already satisfied: sklearn-crfsuite in /opt/conda/lib/python3.10/site-packages (from pyvi) (0.5.0)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.15.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.4)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.8.30)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (3.5.0)\nRequirement already satisfied: python-crfsuite>=0.9.7 in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (0.9.11)\nRequirement already satisfied: tabulate>=0.4.2 in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (0.9.0)\nfatal: destination path 'AIO_RAGforJack' already exists and is not an empty directory.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom pyvi import ViTokenizer\nimport re\nimport unidecode\nimport gdown\n\ngdown.download_folder('https://drive.google.com/drive/folders/1XpqF_ejSmQQJ4IsO38hJDZgMWLZelJyW?usp=sharing',quiet = False)","metadata":{"id":"MuyuWTL6gGRy","execution":{"iopub.status.busy":"2024-10-29T05:36:06.739509Z","iopub.execute_input":"2024-10-29T05:36:06.741021Z","iopub.status.idle":"2024-10-29T05:36:23.57599Z","shell.execute_reply.started":"2024-10-29T05:36:06.740958Z","shell.execute_reply":"2024-10-29T05:36:23.574785Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"Retrieving folder contents\n","output_type":"stream"},{"name":"stdout","text":"Processing file 1MxhsttcL79J68gqrpMcCT_I8A4_3MKLr corpus.csv\nProcessing file 1iXgJHZXXj7B64km0no9IFLtQ8Euy9Xav public_test.csv\nProcessing file 1r6l9Pq5F-Zo6BcQ_Stx91RUBerBouzbi readme.txt\nProcessing file 1w0ZsiIqmEkzzxc83BxEHpyYnl4cyBFWQ train.csv\n","output_type":"stream"},{"name":"stderr","text":"Retrieving folder contents completed\nBuilding directory structure\nBuilding directory structure completed\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1MxhsttcL79J68gqrpMcCT_I8A4_3MKLr\nFrom (redirected): https://drive.google.com/uc?id=1MxhsttcL79J68gqrpMcCT_I8A4_3MKLr&confirm=t&uuid=960a1822-5a84-4e9d-b797-872a0bf31ac5\nTo: /kaggle/working/BKAI/corpus.csv\n100%|██████████| 203M/203M [00:01<00:00, 161MB/s]  \nDownloading...\nFrom: https://drive.google.com/uc?id=1iXgJHZXXj7B64km0no9IFLtQ8Euy9Xav\nTo: /kaggle/working/BKAI/public_test.csv\n100%|██████████| 675k/675k [00:00<00:00, 87.5MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1r6l9Pq5F-Zo6BcQ_Stx91RUBerBouzbi\nTo: /kaggle/working/BKAI/readme.txt\n100%|██████████| 684/684 [00:00<00:00, 2.09MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1w0ZsiIqmEkzzxc83BxEHpyYnl4cyBFWQ\nTo: /kaggle/working/BKAI/train.csv\n100%|██████████| 96.4M/96.4M [00:00<00:00, 116MB/s] \nDownload completed\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"['/kaggle/working/BKAI/corpus.csv',\n '/kaggle/working/BKAI/public_test.csv',\n '/kaggle/working/BKAI/readme.txt',\n '/kaggle/working/BKAI/train.csv']"},"metadata":{}}]},{"cell_type":"code","source":"corpus = pd.read_csv('/kaggle/working/BKAI/corpus.csv')\npublic_test = pd.read_csv('/kaggle/working/BKAI/public_test.csv')\ntrain = pd.read_csv('/kaggle/working/BKAI/train.csv')","metadata":{"id":"SeeEbhaygGR2","execution":{"iopub.status.busy":"2024-10-29T05:38:36.847807Z","iopub.execute_input":"2024-10-29T05:38:36.848593Z","iopub.status.idle":"2024-10-29T05:38:40.986245Z","shell.execute_reply.started":"2024-10-29T05:38:36.848546Z","shell.execute_reply":"2024-10-29T05:38:40.98487Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"file1_path = '/kaggle/working/AIO_RAGforJack/vietnamese-stopwords-dash.txt'  # Thay đổi đường dẫn tới file thứ nhất\nfile2_path = '/kaggle/working/AIO_RAGforJack/vietnamese-stopwords.txt'  # Thay đổi đường dẫn tới file thứ hai\ndef read_stopwords(file_path):\n    stopwords = []\n    with open(file_path, 'r', encoding='utf-8') as file:\n        for line in file:\n            stopword = line.strip()  # Tách theo khoảng trắng\n            stopwords.append(stopword)  # Thêm stopword vào list\n    return stopwords\nstopwords1 = read_stopwords(file1_path)\nstopwords2 = read_stopwords(file2_path)\n\nvietnamese_stopwords = set(stopwords1 + stopwords2)\n\ndef remove_punctuation(text):\n    no_punct_text = re.sub(r'[^\\w\\s]', '', text)  # This will keep Vietnamese letters and spaces\n    return no_punct_text","metadata":{"id":"dz7-DtNhhtPW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corpus['text'] = corpus['text'].apply(lambda x: x.replace('\\n', ' '))\ncorpus['text'] = corpus['text'].apply(lambda x: x.replace('\\t', ' '))\ncorpus['text'] = corpus['text'].apply(lambda x: x.replace('\\r', ' '))\ncorpus['text'] = corpus['text'].apply(lambda x: x.replace('  ', ' '))\ncorpus['text'] = corpus['text'].apply(lambda x: x.lower())\n\npublic_test['question'] = public_test['question'].apply(lambda x: x.replace('\\n', ' '))\npublic_test['question'] = public_test['question'].apply(lambda x: x.replace('\\t', ' '))\npublic_test['question'] = public_test['question'].apply(lambda x: x.replace('\\r', ' '))\npublic_test['question'] = public_test['question'].apply(lambda x: x.replace('  ', ' '))\npublic_test['question'] = public_test['question'].apply(lambda x: x.lower())\n\ntrain['question'] = train['question'].apply(lambda x: x.replace('\\n', ' '))\ntrain['question'] = train['question'].apply(lambda x: x.replace('\\t', ' '))\ntrain['question'] = train['question'].apply(lambda x: x.replace('\\r', ' '))\ntrain['question'] = train['question'].apply(lambda x: x.replace('  ', ' '))\ntrain['question'] = train['question'].apply(lambda x: x.lower())\n\ntrain['context'] = train['context'].apply(lambda x: x.replace('\\n', ' '))\ntrain['context'] = train['context'].apply(lambda x: x.replace('\\t', ' '))\ntrain['context'] = train['context'].apply(lambda x: x.replace('\\r', ' '))\ntrain['context'] = train['context'].apply(lambda x: x.replace('  ', ' '))\ntrain['context'] = train['context'].apply(lambda x: x.lower())\n\ncorpus['text'] = corpus['text'].apply(lambda x: ViTokenizer.tokenize(x))\ncorpus['text'] = corpus['text'].apply(lambda x: remove_punctuation(x))\ncorpus['text'] = corpus['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in vietnamese_stopwords]))\ncorpus['text'] = corpus['text'].apply(lambda x: unidecode.unidecode(x))\n\npublic_test['question'] = public_test['question'].apply(lambda x: ViTokenizer.tokenize(x))\npublic_test['question'] = public_test['question'].apply(lambda x: remove_punctuation(x))\npublic_test['question'] = public_test['question'].apply(lambda x: ' '.join([word for word in x.split() if word not in vietnamese_stopwords]))\npublic_test['question'] = public_test['question'].apply(lambda x: unidecode.unidecode(x))\n\ntrain['question'] = train['question'].apply(lambda x: ViTokenizer.tokenize(x))\ntrain['question'] = train['question'].apply(lambda x: remove_punctuation(x))\ntrain['question'] = train['question'].apply(lambda x: ' '.join([word for word in x.split() if word not in vietnamese_stopwords]))\ntrain['question'] = train['question'].apply(lambda x: unidecode.unidecode(x))\n\ntrain['context'] = train['context'].apply(lambda x: ViTokenizer.tokenize(x))\ntrain['context'] = train['context'].apply(lambda x: remove_punctuation(x))\ntrain['context'] = train['context'].apply(lambda x: ' '.join([word for word in x.split() if word not in vietnamese_stopwords]))\ntrain['context'] = train['context'].apply(lambda x: unidecode.unidecode(x))\n\n\n","metadata":{"id":"6oC361-JgGR3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.to_csv('/kaggle/working/train.csv', index=False)\npublic_test.to_csv('/kaggle/working/public_test.csv', index=False)\ncorpus.to_csv('/kaggle/working/corpus.csv', index=False)","metadata":{"id":"QIquZJG_gGR5"},"execution_count":null,"outputs":[]}]}