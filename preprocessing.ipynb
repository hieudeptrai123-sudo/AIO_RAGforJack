{"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.5"},"colab":{"provenance":[],"include_colab_link":true},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<a href=\"https://www.kaggle.com/code/hieunguyen2208/preprocessing\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"/></a> \n<a href=\"https://colab.research.google.com/github/hieudeptrai123-sudo/AIO_RAGforJack/blob/main/Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"cell_type":"code","source":"!pip install pyvi unidecode\n!git clone https://github.com/hieudeptrai123-sudo/AIO_RAGforJack.git","metadata":{"id":"oY5DB0z2hKi4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom pyvi import ViTokenizer\nimport re\nimport unidecode\nimport gdown\n\ngdown.download_folder('https://drive.google.com/drive/folders/1XpqF_ejSmQQJ4IsO38hJDZgMWLZelJyW?usp=sharing',quiet = False)","metadata":{"id":"MuyuWTL6gGRy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corpus = pd.read_csv('\\kaggle\\working\\BKAI\\corpus.csv')\npublic_test = pd.read_csv('\\kaggle\\working\\BKAI\\public_test.csv')\ntrain = pd.read_csv('\\kaggle\\working\\BKAI\\train.csv')","metadata":{"id":"SeeEbhaygGR2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file1_path = '\\kaggle\\working\\AIO_RAGforJack\\vietnamese-stopwords-dash.txt'  # Thay đổi đường dẫn tới file thứ nhất\nfile2_path = '\\kaggle\\working\\AIO_RAGforJack\\vietnamese-stopwords.txt'  # Thay đổi đường dẫn tới file thứ hai\ndef read_stopwords(file_path):\n    stopwords = []\n    with open(file_path, 'r', encoding='utf-8') as file:\n        for line in file:\n            stopword = line.strip()  # Tách theo khoảng trắng\n            stopwords.append(stopword)  # Thêm stopword vào list\n    return stopwords\nstopwords1 = read_stopwords(file1_path)\nstopwords2 = read_stopwords(file2_path)\n\nvietnamese_stopwords = set(stopwords1 + stopwords2)\n\ndef remove_punctuation(text):\n    no_punct_text = re.sub(r'[^\\w\\s]', '', text)  # This will keep Vietnamese letters and spaces\n    return no_punct_text","metadata":{"id":"dz7-DtNhhtPW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corpus['text'] = corpus['text'].apply(lambda x: x.replace('\\n', ' '))\ncorpus['text'] = corpus['text'].apply(lambda x: x.replace('\\t', ' '))\ncorpus['text'] = corpus['text'].apply(lambda x: x.replace('\\r', ' '))\ncorpus['text'] = corpus['text'].apply(lambda x: x.replace('  ', ' '))\ncorpus['text'] = corpus['text'].apply(lambda x: x.lower())\n\npublic_test['question'] = public_test['question'].apply(lambda x: x.replace('\\n', ' '))\npublic_test['question'] = public_test['question'].apply(lambda x: x.replace('\\t', ' '))\npublic_test['question'] = public_test['question'].apply(lambda x: x.replace('\\r', ' '))\npublic_test['question'] = public_test['question'].apply(lambda x: x.replace('  ', ' '))\npublic_test['question'] = public_test['question'].apply(lambda x: x.lower())\n\ntrain['question'] = train['question'].apply(lambda x: x.replace('\\n', ' '))\ntrain['question'] = train['question'].apply(lambda x: x.replace('\\t', ' '))\ntrain['question'] = train['question'].apply(lambda x: x.replace('\\r', ' '))\ntrain['question'] = train['question'].apply(lambda x: x.replace('  ', ' '))\ntrain['question'] = train['question'].apply(lambda x: x.lower())\n\ntrain['context'] = train['context'].apply(lambda x: x.replace('\\n', ' '))\ntrain['context'] = train['context'].apply(lambda x: x.replace('\\t', ' '))\ntrain['context'] = train['context'].apply(lambda x: x.replace('\\r', ' '))\ntrain['context'] = train['context'].apply(lambda x: x.replace('  ', ' '))\ntrain['context'] = train['context'].apply(lambda x: x.lower())\n\ncorpus['text'] = corpus['text'].apply(lambda x: ViTokenizer.tokenize(x))\ncorpus['text'] = corpus['text'].apply(lambda x: remove_punctuation(x))\ncorpus['text'] = corpus['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in vietnamese_stopwords]))\ncorpus['text'] = corpus['text'].apply(lambda x: unidecode.unidecode(x))\n\npublic_test['question'] = public_test['question'].apply(lambda x: ViTokenizer.tokenize(x))\npublic_test['question'] = public_test['question'].apply(lambda x: remove_punctuation(x))\npublic_test['question'] = public_test['question'].apply(lambda x: ' '.join([word for word in x.split() if word not in vietnamese_stopwords]))\npublic_test['question'] = public_test['question'].apply(lambda x: unidecode.unidecode(x))\n\ntrain['question'] = train['question'].apply(lambda x: ViTokenizer.tokenize(x))\ntrain['question'] = train['question'].apply(lambda x: remove_punctuation(x))\ntrain['question'] = train['question'].apply(lambda x: ' '.join([word for word in x.split() if word not in vietnamese_stopwords]))\ntrain['question'] = train['question'].apply(lambda x: unidecode.unidecode(x))\n\ntrain['context'] = train['context'].apply(lambda x: ViTokenizer.tokenize(x))\ntrain['context'] = train['context'].apply(lambda x: remove_punctuation(x))\ntrain['context'] = train['context'].apply(lambda x: ' '.join([word for word in x.split() if word not in vietnamese_stopwords]))\ntrain['context'] = train['context'].apply(lambda x: unidecode.unidecode(x))\n\n\n","metadata":{"id":"6oC361-JgGR3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.to_csv('\\kaggle\\working\\train.csv', index=False)\npublic_test.to_csv('\\kaggle\\working\\public_test.csv', index=False)\ncorpus.to_csv('\\kaggle\\working\\corpus.csv', index=False)","metadata":{"id":"QIquZJG_gGR5"},"execution_count":null,"outputs":[]}]}
